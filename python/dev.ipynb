{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d94f922-801c-4f2a-880e-7ae29f3c5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ipython-autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext autotime\n",
    "%config Completer.use_jedi = False\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb03dde-6125-4362-a57a-c440e12a5c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import clickhouse_connect\n",
    "\n",
    "client = clickhouse_connect.get_client(host=\"localhost\")\n",
    "query = \"\"\"\n",
    "SELECT\n",
    "    p.id AS post_id,\n",
    "    p.by AS post_author,\n",
    "    p.time AS post_time,\n",
    "    p.title AS post_title,\n",
    "    p.text AS post_text,\n",
    "    c.id AS comment_id,\n",
    "    c.by AS comment_author,\n",
    "    c.time AS comment_time,\n",
    "    c.text AS comment_text\n",
    "FROM\n",
    "    hacker_news p\n",
    "JOIN\n",
    "    hacker_news c ON c.parent = p.id\n",
    "WHERE\n",
    "    p.id IN (\n",
    "        36643772,  -- 2024\n",
    "        34125628,  -- 2023\n",
    "        29746236,  -- 2022\n",
    "        25594068,  -- 2021\n",
    "        21802596,  -- 2020\n",
    "        18753859,  -- 2019\n",
    "        16007988,  -- 2018\n",
    "        10809767,  -- 2016\n",
    "        8822723,   -- 2015\n",
    "        6994370,   -- 2014\n",
    "        3395201,   -- 2012\n",
    "        1970023,   -- 2011\n",
    "        1025681    -- 2010\n",
    "    )\n",
    "    AND c.type = 'comment'\n",
    "ORDER BY\n",
    "    p.time DESC, c.time DESC\n",
    "\"\"\"\n",
    "df = client.query_df(query)\n",
    "df = df.sort_values(\"comment_time\").reset_index(drop=True)\n",
    "df.to_parquet(\"df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54766bf-c3d0-42be-a6cd-0735c21a6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"df.parquet\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a41741-c487-432d-ae59-e2d6a3cb0757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.comment_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa0aaa3-dfc3-4d7d-953c-2a5bc27c3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small hack from Claude to get the dates from posts\n",
    "predictions_dates = {\n",
    "    \"Ask HN: What are your predictions for 2023?\": {\n",
    "        \"creation_date\": \"2022-12-31\",\n",
    "        \"evaluation_date\": \"2024-01-01\",\n",
    "    },\n",
    "    \"Ask HN: What are you predictions for 2022?\": {\n",
    "        \"creation_date\": \"2021-12-31\",\n",
    "        \"evaluation_date\": \"2023-01-01\",\n",
    "    },\n",
    "    \"Ask HN: Predictions for 2021?\": {\n",
    "        \"creation_date\": \"2020-12-31\",\n",
    "        \"evaluation_date\": \"2022-01-01\",\n",
    "    },\n",
    "    \"Ask HN: Predictions for 2020 and the New Decade?\": {\n",
    "        \"creation_date\": \"2019-12-31\",\n",
    "        \"evaluation_date\": \"2021-01-01\",\n",
    "    },\n",
    "    \"Ask HN: Your predictions for 2019?\": {\n",
    "        \"creation_date\": \"2018-12-31\",\n",
    "        \"evaluation_date\": \"2020-01-01\",\n",
    "    },\n",
    "    \"Ask HN: Your predictions for 2018?\": {\n",
    "        \"creation_date\": \"2017-12-31\",\n",
    "        \"evaluation_date\": \"2019-01-01\",\n",
    "    },\n",
    "    \"Ask HN: What are your predictions for 2016?\": {\n",
    "        \"creation_date\": \"2015-12-31\",\n",
    "        \"evaluation_date\": \"2017-01-01\",\n",
    "    },\n",
    "    \"Ask HN: What are your predictions for 2015?\": {\n",
    "        \"creation_date\": \"2014-12-31\",\n",
    "        \"evaluation_date\": \"2016-01-01\",\n",
    "    },\n",
    "    \"Ask HN: What are your 2014 Predictions?\": {\n",
    "        \"creation_date\": \"2013-12-31\",\n",
    "        \"evaluation_date\": \"2015-01-01\",\n",
    "    },\n",
    "    \"Ask HN: Your predictions for 2012?\": {\n",
    "        \"creation_date\": \"2011-12-31\",\n",
    "        \"evaluation_date\": \"2013-01-01\",\n",
    "    },\n",
    "    \"Ask HN: 2011 Predictions\": {\n",
    "        \"creation_date\": \"2010-12-31\",\n",
    "        \"evaluation_date\": \"2012-01-01\",\n",
    "    },\n",
    "    \"Ask HN: A New Decade. Any Predictions?\": {\n",
    "        \"creation_date\": \"2009-12-31\",\n",
    "        \"evaluation_date\": \"2020-01-01\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86167327-c2ca-425c-b0e4-40cb955bf672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For grammar https://github.com/ggerganov/llama.cpp/blob/master/grammars/README.md\n",
    "json_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"predictions\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"text\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The text of the prediction\",\n",
    "                    },\n",
    "                    \"result_evaluation\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The evaluation of the prediction result\",\n",
    "                    },\n",
    "                    \"result_enum\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\n",
    "                            \"correct\",\n",
    "                            \"mostly correct\",\n",
    "                            \"mostly wrong\",\n",
    "                            \"wrong\",\n",
    "                            \"can not be decided\",\n",
    "                        ],\n",
    "                        \"description\": \"The result of the prediction\",\n",
    "                    },\n",
    "                    \"can_be_evaluated_already\": {\n",
    "                        \"type\": \"boolean\",\n",
    "                        \"description\": \"Whether the prediction can be evaluated already\",\n",
    "                    },\n",
    "                    \"category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The general category of the prediction (e.g., Markets, Technology, Politics, etc.)\",\n",
    "                    },\n",
    "                    \"sub_category\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"A more specific sub-category (e.g., S&P, Crypto, AI, etc.)\",\n",
    "                    },\n",
    "                    \"explanation\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Explanation of the result evaluation\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\n",
    "                    \"text\",\n",
    "                    \"result_enum\",\n",
    "                    \"can_be_evaluated_already\",\n",
    "                    \"category\",\n",
    "                    \"sub_category\",\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"predictions\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b601f6e-787b-44c9-a3e6-dc76b5c4f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "# Prompt for https://huggingface.co/NousResearch/Hermes-2-Theta-Llama-3-70B-GGUF\n",
    "core_prompt = \"\"\"You are a helpful assistant that extracts the predictions and evaluates them based on their correctness and answers in JSON. Here's the json schema you must adhere to:\n",
    "<schema>\n",
    "{schema}\n",
    "</schema>\n",
    "Example input:\n",
    "\"Evaluation date: 2024-01-01. Prediction date: 2023-12-31. Text: Markets: S&P -15% by Q2, crypto -40%, Fed funds rate >=5%, energy best performing sector. Ukraine war continues. Layoffs continue.\"\n",
    "    \n",
    "Expected JSON output:\n",
    "    {{\n",
    "        \"predictions\": [\n",
    "            {{\n",
    "                \"text\": \"S&P -15% by Q2\",\n",
    "                \"result_evaluation\": \"The S&P fell by 10% by Q2\",\n",
    "                \"result_enum\": \"mostly correct\",\n",
    "                \"can_be_evaluated_already\": true,\n",
    "                \"category\": \"Markets\",s\n",
    "                \"sub_category\": \"S&P\",\n",
    "                \"explanation\": \"The S&P did not fall by the predicted 15%, but it came close.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"text\": \"Ukraine war continues\",\n",
    "                \"result_evaluation\": \"The war in Ukraine is still ongoing.\",\n",
    "                \"result_enum\": \"correct\",\n",
    "                \"can_be_evaluated_already\": true,\n",
    "                \"category\": \"Politics\",\n",
    "                \"sub_category\": \"Geopolitics\",\n",
    "                \"explanation\": \"The prediction was straightforward and correct as the conflict is still active.\"\n",
    "            }},\n",
    "            {{\n",
    "                \"text\": \"Layoffs continue\",\n",
    "                \"result_evaluation\": \"Layoffs have continued in several sectors, especially in tech.\",\n",
    "                \"result_enum\": \"correct\",\n",
    "                \"can_be_evaluated_already\": true,\n",
    "                \"category\": \"Economy\",\n",
    "                \"sub_category\": \"Employment\",\n",
    "                \"explanation\": \"Data shows a continued trend of layoffs in the tech industry and beyond.\"\n",
    "            }}\n",
    "        ]\n",
    "    }}\"\"\"\n",
    "prompt = f\"\"\"<|im_start|>system\n",
    "{core_prompt}\n",
    "<|im_end|>\"\"\"\n",
    "prompt = prompt.replace(\"{schema}\", json.dumps(json_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882f8db-e1ac-4904-ab19-20a15c803f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "url = \"http://localhost:8080/completion\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "def gen_prompt(t):\n",
    "    dates = predictions_dates[t.post_title]\n",
    "    single_prompt = f\"\"\"<|im_start|>user\n",
    "    Evaluate the following prediction:\n",
    "    Evaluation date: {dates['evaluation_date']}. Prediction date: {dates['creation_date']}. Text: {t.comment_text}<|im_end|><|im_start|>assistant\"\"\"\n",
    "    return single_prompt\n",
    "\n",
    "\n",
    "def parse_incomplete_json(json_string):\n",
    "    # Attempt to find the last complete object\n",
    "    last_complete_object = json_string.rfind(\"}\")\n",
    "    if last_complete_object == -1:\n",
    "        return None  # No complete object found\n",
    "\n",
    "    # Trim the string to the last complete object\n",
    "    trimmed_json = json_string[: last_complete_object + 1]\n",
    "\n",
    "    # Add closing brackets if needed\n",
    "    while trimmed_json.count(\"[\") > trimmed_json.count(\"]\"):\n",
    "        trimmed_json += \"]\"\n",
    "    while trimmed_json.count(\"{\") > trimmed_json.count(\"}\"):\n",
    "        trimmed_json += \"}\"\n",
    "\n",
    "    try:\n",
    "        parsed_data = json.loads(trimmed_json)\n",
    "        return parsed_data\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error parsing JSON: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1adbac-cab7-46d9-9e5f-2f5a05abfbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "def create_predictions_table():\n",
    "    connection = sqlite3.connect(\"predictions.db\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS predictions (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            text TEXT NOT NULL,\n",
    "            result_enum TEXT NOT NULL,\n",
    "            can_be_evaluated_already BOOLEAN NOT NULL,\n",
    "            category TEXT NOT NULL,\n",
    "            sub_category TEXT NOT NULL,\n",
    "            explanation TEXT,\n",
    "            comment_author TEXT NOT NULL,\n",
    "            post_id INTEGER NOT NULL,\n",
    "            comment_id INTEGER NOT NULL\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "\n",
    "\n",
    "def insert_prediction(prediction, model=\"NousResearch/Hermes-2-Theta-Llama-3-70B-GGUF\"):\n",
    "    connection = sqlite3.connect(\"predictions.db\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO predictions (\n",
    "            text,\n",
    "            result_enum,\n",
    "            can_be_evaluated_already,\n",
    "            category,\n",
    "            sub_category,\n",
    "            explanation,\n",
    "            comment_author,\n",
    "            post_id,\n",
    "            comment_id\n",
    "        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\",\n",
    "        (\n",
    "            prediction[\"text\"],\n",
    "            prediction[\"result_enum\"],\n",
    "            prediction[\"can_be_evaluated_already\"],\n",
    "            prediction[\"category\"],\n",
    "            prediction[\"sub_category\"],\n",
    "            prediction.get(\"explanation\", None),\n",
    "            prediction[\"comment_author\"],\n",
    "            prediction[\"post_id\"],\n",
    "            prediction[\"comment_id\"]\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "\n",
    "\n",
    "def comment_id_exists(comment_id):\n",
    "    connection = sqlite3.connect(\"predictions.db\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    cursor.execute(\n",
    "        \"\"\"\n",
    "        SELECT 1 FROM predictions WHERE comment_id = ?\n",
    "    \"\"\",\n",
    "        (comment_id,),\n",
    "    )\n",
    "\n",
    "    result = cursor.fetchone()\n",
    "\n",
    "    connection.close()\n",
    "\n",
    "    return result is not None\n",
    "\n",
    "# create_predictions_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76ec25b-9868-4073-98fc-fb819b77c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tqdm(df.itertuples()):\n",
    "    if comment_id_exists(t.comment_id):\n",
    "        continue\n",
    "    if len(t.comment_text) < 5:\n",
    "        continue\n",
    "    single_prompt = gen_prompt(t)\n",
    "    data = {\n",
    "        # \"prompt\": single_prompt,\n",
    "        \"prompt\": prompt + single_prompt,\n",
    "        \"json_schema\": json_schema,\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    try:\n",
    "        if response.status_code == 200:\n",
    "            json_string = response.json()[\"content\"]\n",
    "            res = parse_incomplete_json(json_string)\n",
    "            pred_list = res[\"predictions\"]\n",
    "            for prediction in pred_list:\n",
    "                insert_prediction(\n",
    "                    {\n",
    "                        **prediction,\n",
    "                        **{\n",
    "                            \"comment_author\": t.comment_author,\n",
    "                            \"post_id\": t.post_id,\n",
    "                            \"comment_id\": t.comment_id,\n",
    "                        },\n",
    "                    }\n",
    "                )\n",
    "            print(pred_list)\n",
    "        else:\n",
    "            print(f\"Request failed with status code {response.status_code}\")\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(f\"error {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce70f9c-72f8-4d00-99cf-a689fd0aa797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "conn = sqlite3.connect(\"predictions.db\")\n",
    "df = pd.read_sql_query(\"SELECT * FROM predictions\", conn)\n",
    "conn.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba366a2-fff2-4700-8529-42183d0abecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.text.str.lower().str.contains(\"bitcoin\")].result_enum.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a0ef1b-e94a-4255-8c08-5297d42c4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.can_be_evaluated_already = df.can_be_evaluated_already.astype(bool)\n",
    "df = df[df.text != \"\"]\n",
    "df = df.iloc[:, 1:]\n",
    "data = df.to_dict(\"records\")\n",
    "ts_content = \"export default \" + json.dumps(data, indent=2) + \";\"\n",
    "with open(\"data.ts\", \"w\") as f:\n",
    "    f.write(ts_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9996494-3658-4c6f-b27e-63fe94981c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_success_rate(group):\n",
    "    total = len(group)\n",
    "    correct = sum(group == \"correct\")\n",
    "    mostly_correct = sum(group == \"mostly correct\")\n",
    "    success_rate = (correct + 0.5 * mostly_correct) / total\n",
    "    return success_rate, total\n",
    "\n",
    "\n",
    "MIN_PREDICTIONS = 10\n",
    "\n",
    "# Weighted success rate for categories\n",
    "category_stats = df.groupby(\"category\")[\"result_enum\"].apply(calculate_success_rate)\n",
    "category_stats = pd.DataFrame(\n",
    "    category_stats.tolist(),\n",
    "    index=category_stats.index,\n",
    "    columns=[\"success_rate\", \"total_predictions\"],\n",
    ")\n",
    "category_stats = category_stats[category_stats[\"total_predictions\"] >= MIN_PREDICTIONS]\n",
    "category_weighted_score = category_stats[\"success_rate\"] * np.log1p(\n",
    "    category_stats[\"total_predictions\"]\n",
    ")\n",
    "top_10_categories = category_weighted_score.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Weighted success rate for authors\n",
    "author_stats = df.groupby(\"comment_author\")[\"result_enum\"].apply(calculate_success_rate)\n",
    "author_stats = pd.DataFrame(\n",
    "    author_stats.tolist(),\n",
    "    index=author_stats.index,\n",
    "    columns=[\"success_rate\", \"total_predictions\"],\n",
    ")\n",
    "author_stats = author_stats[author_stats[\"total_predictions\"] >= MIN_PREDICTIONS]\n",
    "author_weighted_score = author_stats[\"success_rate\"] * np.log1p(\n",
    "    author_stats[\"total_predictions\"]\n",
    ")\n",
    "top_10_authors = author_weighted_score.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Print results\n",
    "print(f\"Top 10 categories (minimum {MIN_PREDICTIONS} predictions):\")\n",
    "for category, score in top_10_categories.items():\n",
    "    success_rate = category_stats.loc[category, \"success_rate\"]\n",
    "    total_preds = category_stats.loc[category, \"total_predictions\"]\n",
    "    print(f\"{category}: {success_rate:.2%} success rate, {total_preds} predictions\")\n",
    "\n",
    "print(f\"\\nTop 10 authors (minimum {MIN_PREDICTIONS} predictions):\")\n",
    "for author, score in top_10_authors.items():\n",
    "    success_rate = author_stats.loc[author, \"success_rate\"]\n",
    "    total_preds = author_stats.loc[author, \"total_predictions\"]\n",
    "    example_comment = df[df[\"comment_author\"] == author][\"comment_id\"].iloc[0]\n",
    "    print(\n",
    "        f\"{author}: {success_rate:.2%} success rate, {total_preds} predictions, Example comment ID: {example_comment}\"\n",
    "    )\n",
    "\n",
    "# Additional statistics\n",
    "total_predictions = len(df)\n",
    "overall_success_rate, _ = calculate_success_rate(df[\"result_enum\"])\n",
    "print(f\"\\nTotal predictions: {total_predictions}\")\n",
    "print(f\"Overall success rate: {overall_success_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82defdb5-17f9-4878-8b0a-d17ebbd0e02e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
